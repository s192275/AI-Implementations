{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:35:09.756959Z",
     "iopub.status.busy": "2025-03-17T20:35:09.756640Z",
     "iopub.status.idle": "2025-03-17T20:35:15.751376Z",
     "shell.execute_reply": "2025-03-17T20:35:15.750491Z",
     "shell.execute_reply.started": "2025-03-17T20:35:09.756928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:39:24.969238Z",
     "iopub.status.busy": "2025-03-17T20:39:24.968869Z",
     "iopub.status.idle": "2025-03-17T20:39:25.046719Z",
     "shell.execute_reply": "2025-03-17T20:39:25.045717Z",
     "shell.execute_reply.started": "2025-03-17T20:39:24.969197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'You are using {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Style \n",
    "Bu çalışmada yapay zeka modellerinin özellik çıkarımından yararlanarak sanatsal bir tablo günlük bir resime entegre edilmiştir. Bunun için bir CNN modeli olan VGG19 modelinin belli başlı katmanları seçilerek günlük görüntü ve sanatsal görüntü üzerinden özellik çıkarımı yapılmış, Gram matrisi aracılığıyla kayıp fonksiyonu hesaplanmış ve optimizer fonksiyonuna görüntü girdi olarak verilerek bütün bu işlemlerin görüntü üzerinden olması sağlanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:47:33.183493Z",
     "iopub.status.busy": "2025-03-17T20:47:33.183200Z",
     "iopub.status.idle": "2025-03-17T20:47:33.188608Z",
     "shell.execute_reply": "2025-03-17T20:47:33.187858Z",
     "shell.execute_reply.started": "2025-03-17T20:47:33.183471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VisualModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(VisualModel, self).__init__()\n",
    "        self.selected_layers = [0, 5, 10, 19, 28] #Makalede seçilen katman numaraları\n",
    "        self.model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
    "        self.feats = self.model.features[:29]\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for layer_num, layer in enumerate(self.feats):\n",
    "            x = layer(x) #Gelen görüntü her katmandan geçirilip sadece belli başlı katmandaki özellikleri seçilecektir. Bütün katmanlardan geçirmeyip sadece seçilecek katmanları eklersek istenilen sonucu alamadık.\n",
    "            if layer_num in self.selected_layers:\n",
    "                features.append(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:47:33.958989Z",
     "iopub.status.busy": "2025-03-17T20:47:33.958636Z",
     "iopub.status.idle": "2025-03-17T20:47:35.676736Z",
     "shell.execute_reply": "2025-03-17T20:47:35.676052Z",
     "shell.execute_reply.started": "2025-03-17T20:47:33.958959Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisualModel(\n",
       "  (model): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (feats): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = VisualModel().to(device)\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:47:47.088631Z",
     "iopub.status.busy": "2025-03-17T20:47:47.088350Z",
     "iopub.status.idle": "2025-03-17T20:47:47.092578Z",
     "shell.execute_reply": "2025-03-17T20:47:47.091565Z",
     "shell.execute_reply.started": "2025-03-17T20:47:47.088610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_size = 200\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size = (img_size, img_size)),\n",
    "    transforms.ToTensor()\n",
    "    #Normalize işlemi yapmadık normalizeli haliyle resimleri tersine çevirmemiz gerekirdi buna gerek yok.\n",
    "    #transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:47:48.369787Z",
     "iopub.status.busy": "2025-03-17T20:47:48.369392Z",
     "iopub.status.idle": "2025-03-17T20:47:48.374020Z",
     "shell.execute_reply": "2025-03-17T20:47:48.373036Z",
     "shell.execute_reply.started": "2025-03-17T20:47:48.369748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_image(img_path, transform = None):\n",
    "  img = Image.open(img_path).convert(\"RGB\")\n",
    "  if transform:\n",
    "    img = transform(img).unsqueeze(0)\n",
    "  return img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:47:50.481966Z",
     "iopub.status.busy": "2025-03-17T20:47:50.481620Z",
     "iopub.status.idle": "2025-03-17T20:47:50.670145Z",
     "shell.execute_reply": "2025-03-17T20:47:50.669226Z",
     "shell.execute_reply.started": "2025-03-17T20:47:50.481939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "original_image = load_image(\"/kaggle/input/vst-dataset/1.png\", transform = transform)\n",
    "generated_image = load_image(\"/kaggle/input/vst-dataset/1.png\", transform = transform).clone().requires_grad_(True)\n",
    "style_image = load_image(\"/kaggle/input/vst-dataset/starry_night.jpg\", transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T20:48:02.176455Z",
     "iopub.status.busy": "2025-03-17T20:48:02.176116Z",
     "iopub.status.idle": "2025-03-17T20:48:03.895623Z",
     "shell.execute_reply": "2025-03-17T20:48:03.894703Z",
     "shell.execute_reply.started": "2025-03-17T20:48:02.176427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = VisualModel().to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:06.403759Z",
     "iopub.status.busy": "2025-03-17T18:47:06.403340Z",
     "iopub.status.idle": "2025-03-17T18:59:26.054948Z",
     "shell.execute_reply": "2025-03-17T18:59:26.054024Z",
     "shell.execute_reply.started": "2025-03-17T18:47:06.403720Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/10000], Total Loss: 13814236.0000\n",
      "Step [200/10000], Total Loss: 691643.6875\n",
      "Step [400/10000], Total Loss: 332796.0938\n",
      "Step [600/10000], Total Loss: 215951.3438\n",
      "Step [800/10000], Total Loss: 148867.4219\n",
      "Step [1000/10000], Total Loss: 108951.5547\n",
      "Step [1200/10000], Total Loss: 87261.8047\n",
      "Step [1400/10000], Total Loss: 75337.5703\n",
      "Step [1600/10000], Total Loss: 67608.5000\n",
      "Step [1800/10000], Total Loss: 61964.7305\n",
      "Step [2000/10000], Total Loss: 57452.6211\n",
      "Step [2200/10000], Total Loss: 53689.2773\n",
      "Step [2400/10000], Total Loss: 50507.9648\n",
      "Step [2600/10000], Total Loss: 47692.2539\n",
      "Step [2800/10000], Total Loss: 45229.3711\n",
      "Step [3000/10000], Total Loss: 43053.9180\n",
      "Step [3200/10000], Total Loss: 41145.9453\n",
      "Step [3400/10000], Total Loss: 39472.9375\n",
      "Step [3600/10000], Total Loss: 37928.5430\n",
      "Step [3800/10000], Total Loss: 36544.1445\n",
      "Step [4000/10000], Total Loss: 35282.7305\n",
      "Step [4200/10000], Total Loss: 34118.4648\n",
      "Step [4400/10000], Total Loss: 33043.0586\n",
      "Step [4600/10000], Total Loss: 32027.8555\n",
      "Step [4800/10000], Total Loss: 31093.0645\n",
      "Step [5000/10000], Total Loss: 30214.6777\n",
      "Step [5200/10000], Total Loss: 29407.4043\n",
      "Step [5400/10000], Total Loss: 28621.8359\n",
      "Step [5600/10000], Total Loss: 27906.4023\n",
      "Step [5800/10000], Total Loss: 27231.2891\n",
      "Step [6000/10000], Total Loss: 26588.7539\n",
      "Step [6200/10000], Total Loss: 25958.4336\n",
      "Step [6400/10000], Total Loss: 25351.6582\n",
      "Step [6600/10000], Total Loss: 24800.3359\n",
      "Step [6800/10000], Total Loss: 24309.5996\n",
      "Step [7000/10000], Total Loss: 23797.4609\n",
      "Step [7200/10000], Total Loss: 23333.0781\n",
      "Step [7400/10000], Total Loss: 22900.7910\n",
      "Step [7600/10000], Total Loss: 22521.2305\n",
      "Step [7800/10000], Total Loss: 22156.2500\n",
      "Step [8000/10000], Total Loss: 21838.0625\n",
      "Step [8200/10000], Total Loss: 21526.9824\n",
      "Step [8400/10000], Total Loss: 21226.4609\n",
      "Step [8600/10000], Total Loss: 20970.5371\n",
      "Step [8800/10000], Total Loss: 20679.5781\n",
      "Step [9000/10000], Total Loss: 20504.1934\n",
      "Step [9200/10000], Total Loss: 20324.1621\n",
      "Step [9400/10000], Total Loss: 20075.2051\n",
      "Step [9600/10000], Total Loss: 19880.9785\n",
      "Step [9800/10000], Total Loss: 19740.1387\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "# Optimizasyon döngüsü\n",
    "to_pil_image = ToPILImage()  # Tensörü görüntüye çevirmek için\n",
    "\n",
    "num_steps = 10000\n",
    "learning_rate = 0.001\n",
    "alpha = 1\n",
    "beta = 0.01\n",
    "optimizer = torch.optim.Adam([generated_image], lr = learning_rate)\n",
    "for step in range(num_steps):\n",
    "  #Orijinal resim, üretilecek resim ve stil resmi modelden geçirilerek feature çıkarılması sağlanır.\n",
    "  generated_features = model(generated_image)\n",
    "  original_features = model(original_image)\n",
    "  style_features = model(style_image)\n",
    "  #Tabi bunların her birinin kaybı da olacaktır.\n",
    "  style_loss = 0\n",
    "  original_loss = 0\n",
    "  generated_loss = 0\n",
    "  for gen_feat, og_feat, style_feat in zip(generated_features, original_features, style_features):\n",
    "    batch_size, channel, height, width = gen_feat.shape\n",
    "    #Makalede de bahsedildiği üzere orijinal içerik kaybı MSE dir Bu oluşturulan resim kaybına eklenir.\n",
    "    original_loss = torch.mean((gen_feat - og_feat) ** 2)\n",
    "    generated_loss += original_loss\n",
    "    #Gram matrisi\n",
    "    G = torch.mm(gen_feat.view(channel, height * width), gen_feat.view(channel, height * width).t())\n",
    "    A = torch.mm(style_feat.view(channel, height * width), style_feat.view(channel, height * width).t())\n",
    "    style_loss += torch.mean((G - A) ** 2)\n",
    "  total_loss = alpha * style_loss + beta * generated_loss\n",
    "  optimizer.zero_grad()\n",
    "  total_loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if step % 200 == 0:\n",
    "      print(f\"Step [{step}/{num_steps}], Total Loss: {total_loss.item():.4f}\")\n",
    "      img_to_save = to_pil_image(generated_image.squeeze(0).cpu())\n",
    "      img_to_save.save(f\"generated_image_step_{step}.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6894960,
     "sourceId": 11065185,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
