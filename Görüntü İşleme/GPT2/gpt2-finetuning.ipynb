{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13178723,"sourceType":"datasetVersion","datasetId":8351298}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:12.336057Z","iopub.execute_input":"2025-09-26T11:41:12.336294Z","iopub.status.idle":"2025-09-26T11:41:55.591641Z","shell.execute_reply.started":"2025-09-26T11:41:12.336268Z","shell.execute_reply":"2025-09-26T11:41:55.590893Z"}},"outputs":[{"name":"stderr","text":"2025-09-26 11:41:34.563407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758886894.898814      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758886895.004986      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ab7a0edbb6c4271ad648517503bff18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39921bd6da1446d18d25bc9decf27af6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f00014f1338a439987504b8de52cbc63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"509078d6d81343989c8ec15418f27391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dce73121a21c4cfc9a73487ef691d174"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bdbb63a91d7442480478def17ff45d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"155bf82e568c4345bc66988b49ada17c"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"text = \"My name is\"\nencoded_input = tokenizer(text, return_tensors='pt')\ngenerated_text = tokenizer.decode(model.generate(encoded_input['input_ids'], max_new_tokens = 9)[0])\ngenerated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:55.593337Z","iopub.execute_input":"2025-09-26T11:41:55.593789Z","iopub.status.idle":"2025-09-26T11:41:56.245297Z","shell.execute_reply.started":"2025-09-26T11:41:55.593769Z","shell.execute_reply":"2025-09-26T11:41:56.244484Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"\"My name is John. I'm a man of God.\""},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd \nimport tiktoken \ntokenizer = tiktoken.get_encoding(\"gpt2\")\ndf = pd.read_csv(\"/kaggle/input/spam-data/spam.csv\", encoding = \"latin1\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:56.246043Z","iopub.execute_input":"2025-09-26T11:41:56.246240Z","iopub.status.idle":"2025-09-26T11:41:57.152100Z","shell.execute_reply.started":"2025-09-26T11:41:56.246225Z","shell.execute_reply":"2025-09-26T11:41:57.151356Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        v1                                                 v2 Unnamed: 2  \\\n0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n1      ham                      Ok lar... Joking wif u oni...        NaN   \n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n3      ham  U dun say so early hor... U c already then say...        NaN   \n4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n...    ...                                                ...        ...   \n5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n5571   ham                         Rofl. Its true to its name        NaN   \n\n     Unnamed: 3 Unnamed: 4  \n0           NaN        NaN  \n1           NaN        NaN  \n2           NaN        NaN  \n3           NaN        NaN  \n4           NaN        NaN  \n...         ...        ...  \n5567        NaN        NaN  \n5568        NaN        NaN  \n5569        NaN        NaN  \n5570        NaN        NaN  \n5571        NaN        NaN  \n\n[5572 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will Ì_ b going to esplanade fr home?</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df['label'] = df['v1'].map({'ham': 0, 'spam': 1})\ndf['text'] = df['v2']\ndf = df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'v1', 'v2'])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:57.152934Z","iopub.execute_input":"2025-09-26T11:41:57.153211Z","iopub.status.idle":"2025-09-26T11:41:57.176349Z","shell.execute_reply.started":"2025-09-26T11:41:57.153186Z","shell.execute_reply":"2025-09-26T11:41:57.175688Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   label                                               text\n0      0  Go until jurong point, crazy.. Available only ...\n1      0                      Ok lar... Joking wif u oni...\n2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n3      0  U dun say so early hor... U c already then say...\n4      0  Nah I don't think he goes to usf, he lives aro...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:57.177193Z","iopub.execute_input":"2025-09-26T11:41:57.177490Z","iopub.status.idle":"2025-09-26T11:41:57.198220Z","shell.execute_reply.started":"2025-09-26T11:41:57.177448Z","shell.execute_reply":"2025-09-26T11:41:57.197407Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"label\n0    4825\n1     747\nName: count, dtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\ntrain_ratio = int(0.7 * len(shuffled_df)) \nval_ratio = train_ratio + int(0.2 * len(shuffled_df))\n\ntrain_df = shuffled_df[:train_ratio]\nval_df = shuffled_df[train_ratio:val_ratio]\ntest_df = shuffled_df[val_ratio:]\n\nprint(f\"Train set size: {len(train_df)}\")\nprint(f\"Validation set size: {len(val_df)}\")\nprint(f\"Test set size: {len(test_df)}\")\n\nprint(train_df.head())\nprint(val_df.head())\nprint(test_df.head())\n\ntrain_df.to_csv(\"train.csv\", index = False)\nval_df.to_csv(\"val.csv\", index = False)\ntest_df.to_csv(\"test.csv\", index = False) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:57.199144Z","iopub.execute_input":"2025-09-26T11:41:57.199481Z","iopub.status.idle":"2025-09-26T11:41:57.257354Z","shell.execute_reply.started":"2025-09-26T11:41:57.199441Z","shell.execute_reply":"2025-09-26T11:41:57.256396Z"}},"outputs":[{"name":"stdout","text":"Train set size: 3900\nValidation set size: 1114\nTest set size: 558\n   label                                               text\n0      0  Funny fact Nobody teaches volcanoes 2 erupt, t...\n1      0  I sent my scores to sophas and i had to do sec...\n2      1  We know someone who you know that fancies you....\n3      0  Only if you promise your getting out as SOON a...\n4      1  Congratulations ur awarded either å£500 of CD ...\n      label                                               text\n3900      1  You have won a Nokia 7250i. This is what you g...\n3901      1  Sorry! U can not unsubscribe yet. THE MOB offe...\n3902      0          X2  &lt;#&gt; . Are you going to get that\n3903      1  network operator. The service is free. For T &...\n3904      0  Is there coming friday is leave for pongal?do ...\n      label                                               text\n5014      0                Yeah why not, is the gang all ready\n5015      0             No message..no responce..what happend?\n5016      0  Ron say fri leh. N he said ding tai feng cant ...\n5017      0               K come to nordstrom when you're done\n5018      0  Damn, can you make it tonight or do you want t...\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import Tuple # Import Tuple\n\nclass SpamDataset(Dataset):\n  def __init__(self, csv_file:str, tokenizer:tiktoken.core.Encoding, max_length = None, pad_token_id:int=50256) -> None:\n    super().__init__()\n    self.csv_data = pd.read_csv(csv_file)\n    self.encoded_texts = [tokenizer.encode(text) for text in self.csv_data['text']]\n    if max_length is None:\n      self.max_length = self._longest_encoded_length()\n    else:\n      self.max_length = max_length\n      self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n    self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n\n  def __len__(self) -> int:\n    return len(self.csv_data)\n\n  def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:\n    encoded = self.encoded_texts[idx]\n    label = self.csv_data.iloc[idx][\"label\"]\n    return (\n            torch.tensor(encoded, dtype=torch.long),\n            torch.tensor(label, dtype=torch.long)\n        )\n\n  def _longest_encoded_length(self)->int:\n    max_length = 0\n    for encoded_text in self.encoded_texts:\n      encoded_length = len(encoded_text)\n      if encoded_length > max_length:\n        max_length = encoded_length\n    return max_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:41:57.259431Z","iopub.execute_input":"2025-09-26T11:41:57.259787Z","iopub.status.idle":"2025-09-26T11:41:57.268866Z","shell.execute_reply.started":"2025-09-26T11:41:57.259757Z","shell.execute_reply":"2025-09-26T11:41:57.267955Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset= SpamDataset(csv_file=\"/kaggle/working/train.csv\",max_length=None,tokenizer=tokenizer)\ntest_dataset= SpamDataset(csv_file=\"/kaggle/working/test.csv\",max_length=None,tokenizer=tokenizer)\nval_dataset=SpamDataset(csv_file=\"/kaggle/working/val.csv\",max_length=None,tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:42:30.012762Z","iopub.execute_input":"2025-09-26T11:42:30.013540Z","iopub.status.idle":"2025-09-26T11:42:30.134342Z","shell.execute_reply.started":"2025-09-26T11:42:30.013481Z","shell.execute_reply":"2025-09-26T11:42:30.133611Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nnum_workers= 0\nbatch_size=8\ntrain_loader=DataLoader(\n    dataset=train_dataset,\n    shuffle=True,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    drop_last=True\n)\ntest_loader=DataLoader(\n    dataset=test_dataset,\n    shuffle=True,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    drop_last=False\n)\nval_loader=DataLoader(\n    dataset=val_dataset,\n    shuffle=True,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    drop_last=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:43:03.485388Z","iopub.execute_input":"2025-09-26T11:43:03.486182Z","iopub.status.idle":"2025-09-26T11:43:03.492402Z","shell.execute_reply.started":"2025-09-26T11:43:03.486141Z","shell.execute_reply":"2025-09-26T11:43:03.491717Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#Parametreleri donduralım zaten eğitilmiş\nfor param in model.parameters():\n  param_requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:43:06.025213Z","iopub.execute_input":"2025-09-26T11:43:06.025577Z","iopub.status.idle":"2025-09-26T11:43:06.030804Z","shell.execute_reply.started":"2025-09-26T11:43:06.025552Z","shell.execute_reply":"2025-09-26T11:43:06.029777Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch.nn as nn\nnum_class = 2\nmodel.classifier = nn.Linear(in_features=50257, out_features=num_class, bias=False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:43:07.976192Z","iopub.execute_input":"2025-09-26T11:43:07.976530Z","iopub.status.idle":"2025-09-26T11:43:07.987675Z","shell.execute_reply.started":"2025-09-26T11:43:07.976497Z","shell.execute_reply":"2025-09-26T11:43:07.986941Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n  (classifier): Linear(in_features=50257, out_features=2, bias=False)\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def train_model(model, train_dataloader, val_dataloader, optimizer, loss_fn, device, epochs):\n    model = model.to(device)\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n\n        for text, label in train_dataloader:\n            text = text.to(device)\n            label = label.to(device)\n\n            optimizer.zero_grad()\n            # Forward pass\n            outputs = model(text)\n            logits = outputs.logits\n            classification_logits = model.classifier(logits[:, -1, :])\n\n            # Loss\n            batch_loss = loss_fn(classification_logits, label)\n            batch_loss.backward()\n            optimizer.step()\n\n            train_loss += batch_loss.item()\n\n            # Accuracy\n            preds = classification_logits.argmax(dim=1)\n            train_correct += (preds == label).sum().item()\n            train_total += label.size(0)\n\n        avg_train_loss = train_loss / len(train_dataloader)\n        train_accuracy = train_correct / train_total\n        print(f\"Epoch: {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n\n        # Validation\n        if val_dataloader is not None:\n            model.eval()\n            val_loss = 0.0\n            val_correct = 0\n            val_total = 0\n            with torch.no_grad():\n                for text, label in val_dataloader:\n                    text = text.to(device)\n                    label = label.to(device)\n\n                    outputs = model(text)\n                    logits = outputs.logits\n                    classification_logits = model.classifier(logits[:, -1, :])\n\n                    val_loss += loss_fn(classification_logits, label).item()\n\n                    preds = classification_logits.argmax(dim=1)\n                    val_correct += (preds == label).sum().item()\n                    val_total += label.size(0)\n\n            avg_val_loss = val_loss / len(val_dataloader)\n            val_accuracy = val_correct / val_total\n            print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Acc: {val_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:43:16.346356Z","iopub.execute_input":"2025-09-26T11:43:16.347073Z","iopub.status.idle":"2025-09-26T11:43:16.358925Z","shell.execute_reply.started":"2025-09-26T11:43:16.347037Z","shell.execute_reply":"2025-09-26T11:43:16.358214Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_model(\n    model,\n    train_loader,\n    val_loader,\n    optimizer=torch.optim.AdamW(model.parameters(), lr=1e-3),\n    loss_fn=nn.CrossEntropyLoss(),\n    device='cuda' if torch.cuda.is_available() else 'cpu',\n    epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:43:24.609119Z","iopub.execute_input":"2025-09-26T11:43:24.609423Z","iopub.status.idle":"2025-09-26T12:29:53.364773Z","shell.execute_reply.started":"2025-09-26T11:43:24.609402Z","shell.execute_reply":"2025-09-26T12:29:53.363986Z"}},"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\nYou may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1/10 | Train Loss: 45.2709 | Train Acc: 0.7970\nValidation Loss: 0.3512 | Validation Acc: 0.8959\nEpoch: 2/10 | Train Loss: 0.8161 | Train Acc: 0.9289\nValidation Loss: 1.8506 | Validation Acc: 0.9749\nEpoch: 3/10 | Train Loss: 7.8681 | Train Acc: 0.9559\nValidation Loss: 2.7765 | Validation Acc: 0.9740\nEpoch: 4/10 | Train Loss: 1.1738 | Train Acc: 0.9772\nValidation Loss: 0.4992 | Validation Acc: 0.9794\nEpoch: 5/10 | Train Loss: 0.6738 | Train Acc: 0.9792\nValidation Loss: 1.1088 | Validation Acc: 0.9811\nEpoch: 6/10 | Train Loss: 219.1382 | Train Acc: 0.9720\nValidation Loss: 125.9889 | Validation Acc: 0.9749\nEpoch: 7/10 | Train Loss: 17.4881 | Train Acc: 0.9833\nValidation Loss: 15.9788 | Validation Acc: 0.9776\nEpoch: 8/10 | Train Loss: 4.1706 | Train Acc: 0.9861\nValidation Loss: 4.9801 | Validation Acc: 0.9856\nEpoch: 9/10 | Train Loss: 1.0411 | Train Acc: 0.9926\nValidation Loss: 2.3451 | Validation Acc: 0.9811\nEpoch: 10/10 | Train Loss: 0.8912 | Train Acc: 0.9928\nValidation Loss: 6.9880 | Validation Acc: 0.9811\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n    model.eval()\n\n    # Prepare inputs to the model\n    input_ids = tokenizer.encode(text)\n    supported_context_length = model.transformer.wte.weight.shape[0]\n    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n\n    # Truncate sequences if they too long\n    input_ids = input_ids[:min(max_length, supported_context_length)]\n\n    # Pad sequences to the longest sequence\n    input_ids += [pad_token_id] * (max_length - len(input_ids))\n    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n\n    # Model inference\n    with torch.no_grad():\n        outputs = model(input_tensor)\n        logits = outputs.logits[:, -1, :]  # ModelOutput içinden logits’i alın\n    predicted_label = torch.argmax(logits, dim=-1).item()\n\n    # Return the classified result\n    return \"spam\" if predicted_label == 1 else \"not spam\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:32:51.805444Z","iopub.execute_input":"2025-09-26T12:32:51.805741Z","iopub.status.idle":"2025-09-26T12:32:51.812023Z","shell.execute_reply.started":"2025-09-26T12:32:51.805720Z","shell.execute_reply":"2025-09-26T12:32:51.811211Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ntext_1 = (\n    \"How are you doing ? Are you available at 8?\"\n)\n\nprint(classify_review(\n    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n))\n\ntext_2 = (\n    \"Hey, just wanted to check if we're still on\"\n    \" for dinner tonight? Let me know!\"\n)\n\nprint(classify_review(\n    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:35:02.690381Z","iopub.execute_input":"2025-09-26T12:35:02.691019Z","iopub.status.idle":"2025-09-26T12:35:02.773297Z","shell.execute_reply.started":"2025-09-26T12:35:02.690994Z","shell.execute_reply":"2025-09-26T12:35:02.772738Z"}},"outputs":[{"name":"stdout","text":"not spam\nnot spam\n","output_type":"stream"}],"execution_count":21}]}