{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bazen yapılan işe göre modelleri eğitmek gerekebilir. Bu modeller büyük veri setleri ile eğitildiği için bizim görevimize çabuk uyum sağlayacaklardır. Eğitilmiş model ağırlıklarını kullanarak modelleri kendi görevimiz için eğitebiliriz. Bu işleme Transfer Learning denir. Gelin GPT2 modelini bu iş için kullanalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-26T11:41:12.336294Z",
     "iopub.status.busy": "2025-09-26T11:41:12.336057Z",
     "iopub.status.idle": "2025-09-26T11:41:55.591641Z",
     "shell.execute_reply": "2025-09-26T11:41:55.590893Z",
     "shell.execute_reply.started": "2025-09-26T11:41:12.336268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 11:41:34.563407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758886894.898814      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758886895.004986      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab7a0edbb6c4271ad648517503bff18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39921bd6da1446d18d25bc9decf27af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00014f1338a439987504b8de52cbc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509078d6d81343989c8ec15418f27391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce73121a21c4cfc9a73487ef691d174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdbb63a91d7442480478def17ff45d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155bf82e568c4345bc66988b49ada17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GPT2 kütüphanesi transformers kütüphanesi üzerinden aktarılabilir.\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:41:55.593789Z",
     "iopub.status.busy": "2025-09-26T11:41:55.593337Z",
     "iopub.status.idle": "2025-09-26T11:41:56.245297Z",
     "shell.execute_reply": "2025-09-26T11:41:56.244484Z",
     "shell.execute_reply.started": "2025-09-26T11:41:55.593769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My name is John. I'm a man of God.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modeli örnek bir cümle ile test edelim.\n",
    "text = \"My name is\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "generated_text = tokenizer.decode(model.generate(encoded_input['input_ids'], max_new_tokens = 9)[0])\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:41:56.246240Z",
     "iopub.status.busy": "2025-09-26T11:41:56.246043Z",
     "iopub.status.idle": "2025-09-26T11:41:57.152100Z",
     "shell.execute_reply": "2025-09-26T11:41:57.151356Z",
     "shell.execute_reply.started": "2025-09-26T11:41:56.246225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tiktoken kütüphanesi ile gpt2 tokenizer'ını yükleyelim ve pandas ile csv dosyamızı okuyalım.\n",
    "import pandas as pd \n",
    "import tiktoken \n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "df = pd.read_csv(\"/kaggle/input/spam-data/spam.csv\", encoding = \"latin1\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:41:57.153211Z",
     "iopub.status.busy": "2025-09-26T11:41:57.152934Z",
     "iopub.status.idle": "2025-09-26T11:41:57.176349Z",
     "shell.execute_reply": "2025-09-26T11:41:57.175688Z",
     "shell.execute_reply.started": "2025-09-26T11:41:57.153186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "df['text'] = df['v2']\n",
    "df = df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'v1', 'v2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:41:57.177490Z",
     "iopub.status.busy": "2025-09-26T11:41:57.177193Z",
     "iopub.status.idle": "2025-09-26T11:41:57.198220Z",
     "shell.execute_reply": "2025-09-26T11:41:57.197407Z",
     "shell.execute_reply.started": "2025-09-26T11:41:57.177448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:41:57.199481Z",
     "iopub.status.busy": "2025-09-26T11:41:57.199144Z",
     "iopub.status.idle": "2025-09-26T11:41:57.257354Z",
     "shell.execute_reply": "2025-09-26T11:41:57.256396Z",
     "shell.execute_reply.started": "2025-09-26T11:41:57.199441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 3900\n",
      "Validation set size: 1114\n",
      "Test set size: 558\n",
      "   label                                               text\n",
      "0      0  Funny fact Nobody teaches volcanoes 2 erupt, t...\n",
      "1      0  I sent my scores to sophas and i had to do sec...\n",
      "2      1  We know someone who you know that fancies you....\n",
      "3      0  Only if you promise your getting out as SOON a...\n",
      "4      1  Congratulations ur awarded either å£500 of CD ...\n",
      "      label                                               text\n",
      "3900      1  You have won a Nokia 7250i. This is what you g...\n",
      "3901      1  Sorry! U can not unsubscribe yet. THE MOB offe...\n",
      "3902      0          X2  &lt;#&gt; . Are you going to get that\n",
      "3903      1  network operator. The service is free. For T &...\n",
      "3904      0  Is there coming friday is leave for pongal?do ...\n",
      "      label                                               text\n",
      "5014      0                Yeah why not, is the gang all ready\n",
      "5015      0             No message..no responce..what happend?\n",
      "5016      0  Ron say fri leh. N he said ding tai feng cant ...\n",
      "5017      0               K come to nordstrom when you're done\n",
      "5018      0  Damn, can you make it tonight or do you want t...\n"
     ]
    }
   ],
   "source": [
    "# Veri setini karıştıralım ve eğitim, doğrulama ve test setlerine bölelim.\n",
    "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_ratio = int(0.7 * len(shuffled_df)) \n",
    "val_ratio = train_ratio + int(0.2 * len(shuffled_df))\n",
    "\n",
    "train_df = shuffled_df[:train_ratio]\n",
    "val_df = shuffled_df[train_ratio:val_ratio]\n",
    "test_df = shuffled_df[val_ratio:]\n",
    "\n",
    "print(f\"Train set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(val_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(val_df.head())\n",
    "print(test_df.head())\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index = False)\n",
    "val_df.to_csv(\"val.csv\", index = False)\n",
    "test_df.to_csv(\"test.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:41:57.259787Z",
     "iopub.status.busy": "2025-09-26T11:41:57.259431Z",
     "iopub.status.idle": "2025-09-26T11:41:57.268866Z",
     "shell.execute_reply": "2025-09-26T11:41:57.267955Z",
     "shell.execute_reply.started": "2025-09-26T11:41:57.259757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Veri setini oluşturalım ve encode edelim. En uzun metin uzunluğunu belirleyip tüm metinleri bu uzunluğa pad edelim.\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple \n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "  def __init__(self, csv_file:str, tokenizer:tiktoken.core.Encoding, max_length = None, pad_token_id:int=50256) -> None:\n",
    "    super().__init__()\n",
    "    self.csv_data = pd.read_csv(csv_file)\n",
    "    self.encoded_texts = [tokenizer.encode(text) for text in self.csv_data['text']]\n",
    "    if max_length is None:\n",
    "      self.max_length = self._longest_encoded_length()\n",
    "    else:\n",
    "      self.max_length = max_length\n",
    "      self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
    "    self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.csv_data)\n",
    "\n",
    "  def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    encoded = self.encoded_texts[idx]\n",
    "    label = self.csv_data.iloc[idx][\"label\"]\n",
    "    return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "  def _longest_encoded_length(self)->int:\n",
    "    max_length = 0\n",
    "    for encoded_text in self.encoded_texts:\n",
    "      encoded_length = len(encoded_text)\n",
    "      if encoded_length > max_length:\n",
    "        max_length = encoded_length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:42:30.013540Z",
     "iopub.status.busy": "2025-09-26T11:42:30.012762Z",
     "iopub.status.idle": "2025-09-26T11:42:30.134342Z",
     "shell.execute_reply": "2025-09-26T11:42:30.133611Z",
     "shell.execute_reply.started": "2025-09-26T11:42:30.013481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset= SpamDataset(csv_file=\"/kaggle/working/train.csv\",max_length=None,tokenizer=tokenizer)\n",
    "test_dataset= SpamDataset(csv_file=\"/kaggle/working/test.csv\",max_length=None,tokenizer=tokenizer)\n",
    "val_dataset=SpamDataset(csv_file=\"/kaggle/working/val.csv\",max_length=None,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:43:03.486182Z",
     "iopub.status.busy": "2025-09-26T11:43:03.485388Z",
     "iopub.status.idle": "2025-09-26T11:43:03.492402Z",
     "shell.execute_reply": "2025-09-26T11:43:03.491717Z",
     "shell.execute_reply.started": "2025-09-26T11:43:03.486141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers= 0\n",
    "batch_size=8\n",
    "train_loader=DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "val_loader=DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:43:06.025577Z",
     "iopub.status.busy": "2025-09-26T11:43:06.025213Z",
     "iopub.status.idle": "2025-09-26T11:43:06.030804Z",
     "shell.execute_reply": "2025-09-26T11:43:06.029777Z",
     "shell.execute_reply.started": "2025-09-26T11:43:06.025552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Parametreleri donduralım zaten eğitilmiş\n",
    "for param in model.parameters():\n",
    "  param_requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:43:07.976530Z",
     "iopub.status.busy": "2025-09-26T11:43:07.976192Z",
     "iopub.status.idle": "2025-09-26T11:43:07.987675Z",
     "shell.execute_reply": "2025-09-26T11:43:07.986941Z",
     "shell.execute_reply.started": "2025-09-26T11:43:07.976497Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  (classifier): Linear(in_features=50257, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "num_class = 2\n",
    "model.classifier = nn.Linear(in_features=50257, out_features=num_class, bias=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:43:16.347073Z",
     "iopub.status.busy": "2025-09-26T11:43:16.346356Z",
     "iopub.status.idle": "2025-09-26T11:43:16.358925Z",
     "shell.execute_reply": "2025-09-26T11:43:16.358214Z",
     "shell.execute_reply.started": "2025-09-26T11:43:16.347037Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model train fonksiyonunu oluşturalım\n",
    "def train_model(model, train_dataloader, val_dataloader, optimizer, loss_fn, device, epochs):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for text, label in train_dataloader:\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(text)\n",
    "            logits = outputs.logits\n",
    "            classification_logits = model.classifier(logits[:, -1, :])\n",
    "\n",
    "            # Loss\n",
    "            batch_loss = loss_fn(classification_logits, label)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "\n",
    "            # Accuracy\n",
    "            preds = classification_logits.argmax(dim=1)\n",
    "            train_correct += (preds == label).sum().item()\n",
    "            train_total += label.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        if val_dataloader is not None:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            with torch.no_grad():\n",
    "                for text, label in val_dataloader:\n",
    "                    text = text.to(device)\n",
    "                    label = label.to(device)\n",
    "\n",
    "                    outputs = model(text)\n",
    "                    logits = outputs.logits\n",
    "                    classification_logits = model.classifier(logits[:, -1, :])\n",
    "\n",
    "                    val_loss += loss_fn(classification_logits, label).item()\n",
    "\n",
    "                    preds = classification_logits.argmax(dim=1)\n",
    "                    val_correct += (preds == label).sum().item()\n",
    "                    val_total += label.size(0)\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_dataloader)\n",
    "            val_accuracy = val_correct / val_total\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Acc: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T11:43:24.609423Z",
     "iopub.status.busy": "2025-09-26T11:43:24.609119Z",
     "iopub.status.idle": "2025-09-26T12:29:53.364773Z",
     "shell.execute_reply": "2025-09-26T12:29:53.363986Z",
     "shell.execute_reply.started": "2025-09-26T11:43:24.609402Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 | Train Loss: 45.2709 | Train Acc: 0.7970\n",
      "Validation Loss: 0.3512 | Validation Acc: 0.8959\n",
      "Epoch: 2/10 | Train Loss: 0.8161 | Train Acc: 0.9289\n",
      "Validation Loss: 1.8506 | Validation Acc: 0.9749\n",
      "Epoch: 3/10 | Train Loss: 7.8681 | Train Acc: 0.9559\n",
      "Validation Loss: 2.7765 | Validation Acc: 0.9740\n",
      "Epoch: 4/10 | Train Loss: 1.1738 | Train Acc: 0.9772\n",
      "Validation Loss: 0.4992 | Validation Acc: 0.9794\n",
      "Epoch: 5/10 | Train Loss: 0.6738 | Train Acc: 0.9792\n",
      "Validation Loss: 1.1088 | Validation Acc: 0.9811\n",
      "Epoch: 6/10 | Train Loss: 219.1382 | Train Acc: 0.9720\n",
      "Validation Loss: 125.9889 | Validation Acc: 0.9749\n",
      "Epoch: 7/10 | Train Loss: 17.4881 | Train Acc: 0.9833\n",
      "Validation Loss: 15.9788 | Validation Acc: 0.9776\n",
      "Epoch: 8/10 | Train Loss: 4.1706 | Train Acc: 0.9861\n",
      "Validation Loss: 4.9801 | Validation Acc: 0.9856\n",
      "Epoch: 9/10 | Train Loss: 1.0411 | Train Acc: 0.9926\n",
      "Validation Loss: 2.3451 | Validation Acc: 0.9811\n",
      "Epoch: 10/10 | Train Loss: 0.8912 | Train Acc: 0.9928\n",
      "Validation Loss: 6.9880 | Validation Acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=1e-3),\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T12:32:51.805741Z",
     "iopub.status.busy": "2025-09-26T12:32:51.805444Z",
     "iopub.status.idle": "2025-09-26T12:32:51.812023Z",
     "shell.execute_reply": "2025-09-26T12:32:51.811211Z",
     "shell.execute_reply.started": "2025-09-26T12:32:51.805720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.transformer.wte.weight.shape[0]\n",
    " \n",
    "    # Eğer çok uzun metin varsa truncate edelim\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # En uzun metni padleyelim\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        logits = outputs.logits[:, -1, :]  # ModelOutput içinden logits’i alın\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-26T12:35:02.691019Z",
     "iopub.status.busy": "2025-09-26T12:35:02.690381Z",
     "iopub.status.idle": "2025-09-26T12:35:02.773297Z",
     "shell.execute_reply": "2025-09-26T12:35:02.772738Z",
     "shell.execute_reply.started": "2025-09-26T12:35:02.690994Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n",
      "not spam\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "text_1 = (\n",
    "    \"How are you doing ? Are you available at 8?\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n",
    "\n",
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8351298,
     "sourceId": 13178723,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
